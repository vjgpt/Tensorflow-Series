{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"## Train Keras CNN Model on AWS Sagemaker"},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import os\nimport sys\n\nimport numpy as np\nimport sagemaker\nfrom sagemaker.tensorflow import TensorFlow\nimport tensorflow as tf\nfrom tensorflow import keras\nimport boto3\nfrom botocore.exceptions import ClientError"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"# Our SM jobs will use this bucket\nSM_WORKING_S3_BUCKET = \"tensorflow-sagemaker-0028\"\n\nSM_SESSION = sagemaker.Session(default_bucket=SM_WORKING_S3_BUCKET)\nSM_ROLE = sagemaker.get_execution_role()\n\nprint (SM_SESSION)\nprint (SM_ROLE)\n\nTOPDIR = os.getcwd()\n\nEPOCHS = 10\nBATCH_SIZE = 256\nLEARNING_RATE = 0.01\n\nS3_OUTPUT_URI=f\"s3://{SM_WORKING_S3_BUCKET}\"\n"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"# Loading and Saving the dataset\n\nfashion_mnist = keras.datasets.fashion_mnist\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\nos.makedirs(\"./data\", exist_ok = True)\n\nnp.savez('./data/training', image=train_images, label=train_labels)\nnp.savez('./data/validation', image=test_images, label=test_labels)"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"# Upload the dataset to S3 bucket\n\ndef upload_file(file_name, bucket, object_name=None):\n    s3_client = boto3.client('s3')\n    try:\n        response = s3_client.upload_file(file_name, bucket, object_name)\n    except ClientError as e:\n        logging.error(e)\n        return False\n    return True\n\nupload_file('./data/training.npz', SM_WORKING_S3_BUCKET, 'data/training.npz')\nupload_file('./data/validation.npz', SM_WORKING_S3_BUCKET, 'data/validation.npz')"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"# Setting up parameters for Training the model.\n\nmodel_dir = '/opt/ml/model'\n\ntraining_input_path = os.path.join('s3://',SM_WORKING_S3_BUCKET, 'data/training.npz')\nvalidation_input_path = os.path.join('s3://',SM_WORKING_S3_BUCKET, 'data/validation.npz')\n\ntrain_instance_type = 'ml.m4.xlarge'\n#train_instance_type = 'local'\n\n# Path is relative to the src_dir\nhyperparameters = {'epochs' : EPOCHS,\n                   'batch-size' : BATCH_SIZE,\n                   'learning-rate' : LEARNING_RATE\n                  }\n\ninputs = {'training': training_input_path, 'validation': validation_input_path}\nprint(inputs)"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"!pygmentize fashionmnist.py"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"tf_estimator = TensorFlow(entry_point='fashionmnist.py', \n                          role=SM_ROLE,\n                          output_path=S3_OUTPUT_URI,\n                          train_instance_count=1, \n                          train_instance_type=train_instance_type,\n                          framework_version='2.1.0',\n                          py_version='py3',\n                          hyperparameters=hyperparameters\n                         )"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"tf_estimator.fit(inputs)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"## Deploy your model\n\nimport time\n\ntf_endpoint_name = 'tf-fmnist-'+time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n\ntf_predictor = tf_estimator.deploy(initial_instance_count=1,\n                         instance_type='ml.m4.xlarge',\n                         endpoint_name=tf_endpoint_name)"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"%matplotlib inline\nimport random\nimport matplotlib.pyplot as plt\n\nnum_samples = 5\nindices = random.sample(range(test_images.shape[0] - 1), num_samples)\nimages = test_images[indices]/255\nlabels = test_labels[indices]\n\n# datamain= images.reshape(num_samples, 28, 28, 1)\n# data = json.dumps(datamain.tolist())\n# print(datamain.type)\n\n# json_file = open('predictfin.json', 'w')\n# json_file.write(data)\n# json_file.close()\n\n\nfor i in range(num_samples):\n    plt.subplot(1,num_samples,i+1)\n    plt.imshow(images[i].reshape(28, 28), cmap='gray')\n    plt.title(labels[i])\n    plt.axis('off')\n\nprediction = tf_predictor.predict(images.reshape(num_samples, 28, 28, 1))['predictions']\nprediction = np.array(prediction)\npredicted_label = prediction.argmax(axis=1)\nprint('Predicted labels are: {}'.format(predicted_label))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"SM_SESSION.delete_endpoint(endpoint_name=tf_endpoint_name)"},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":"# This is to create an Endpoint from existing Endpoint Configurations.\n\nimport boto3\n\nclient = boto3.client('sagemaker')\n\nresponse = client.create_endpoint(\n    EndpointName='tf-fmnist-2020-05-13-13-58-59',\n    EndpointConfigName='tf-fmnist-2020-05-13-13-58-59'\n)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}